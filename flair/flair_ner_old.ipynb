{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-27 14:35:55,213 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Execution time: 14753.73 seconds\n"
     ]
    }
   ],
   "source": [
    "#!pip install flair\n",
    "import psycopg2\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# Load configuration from YAML file\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Database connection parameters\n",
    "db_config = config['local_db']  # Adjust to 'remote_db' if needed\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(\n",
    "    host=db_config['host'],\n",
    "    port=db_config['port'],\n",
    "    dbname=db_config['database'],\n",
    "    user=db_config['user'],\n",
    "    password=db_config['password']\n",
    ")\n",
    "\n",
    "# Define query parameters\n",
    "query_limit = config.get('query_flair_limit', 2500000)\n",
    "offset = config.get('offset', 0)\n",
    "query_text = 'gold mine'\n",
    "\n",
    "# SQL query to retrieve stories containing the keyword \"gold mine\"\n",
    "story_query = f\"SELECT id, story FROM public.\\\"DJ_NEWS_STORIES\\\" WHERE story LIKE '%{query_text}%' LIMIT {query_limit} OFFSET {offset};\"\n",
    "\n",
    "# Load Flair's pre-trained NER model\n",
    "tagger = SequenceTagger.load(\"ner\")\n",
    "\n",
    "# Function to clean text: removes URLs, HTML tags, punctuation, numbers, and extra whitespace\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # Remove punctuation, digits, and non-printable characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "\n",
    "    return text\n",
    "\n",
    "# Start processing\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute query to retrieve stories\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(story_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# Collect entities and counts\n",
    "unique_entities_set = set()\n",
    "all_entities = set()\n",
    "type_counts = {}\n",
    "total_count = 0\n",
    "\n",
    "# Process each story in the results\n",
    "for row in result:\n",
    "    story_id = row[0]\n",
    "    text = row[1]\n",
    "    \n",
    "    # Clean the story text\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Process cleaned text with Flair NER\n",
    "    sentence = Sentence(cleaned_text)\n",
    "    tagger.predict(sentence)\n",
    "    \n",
    "    # Extract and store relevant entities\n",
    "    for entity in sentence.get_spans(\"ner\"):\n",
    "        if entity.get_label(\"ner\").value in ['ORG', 'LOC', 'PER']:  # Use relevant entity types\n",
    "            entity_type = entity.get_label(\"ner\").value\n",
    "            entity_tuple = (entity.text.strip(), entity_type, story_id)\n",
    "            all_entities.add(entity_tuple)\n",
    "            unique_entities_set.add((entity.text.strip(), entity_type))\n",
    "            \n",
    "            # Update counts for summary\n",
    "            type_counts[entity_type] = type_counts.get(entity_type, 0) + 1\n",
    "            total_count += 1\n",
    "\n",
    "# Convert sets to sorted DataFrames for saving to Excel\n",
    "unique_entities_df = pd.DataFrame(sorted(unique_entities_set), columns=[\"Entity\", \"Tag\"])\n",
    "all_entities_df = pd.DataFrame(sorted(all_entities), columns=[\"Entity\", \"Tag\", \"Story ID\"])\n",
    "summary_df = pd.DataFrame(list(type_counts.items()), columns=[\"Tag\", \"Count\"])\n",
    "summary_df = pd.concat([summary_df, pd.DataFrame([[\"TOTAL\", total_count]], columns=[\"Tag\", \"Count\"])])\n",
    "\n",
    "# Save to Excel with multiple sheets\n",
    "with pd.ExcelWriter(\"recognized_entities_flair.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    unique_entities_df.to_excel(writer, sheet_name=\"Unique Entities\", index=False)\n",
    "    all_entities_df.to_excel(writer, sheet_name=\"All Entities with Story ID\", index=False)\n",
    "    summary_df.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
    "\n",
    "# Close the database connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# Print execution time\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Using cached flair-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting boto3>=1.20.27 (from flair)\n",
      "  Using cached boto3-1.35.49-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
      "  Using cached conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair)\n",
      "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting gdown>=4.4.0 (from flair)\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting huggingface-hub>=0.10.0 (from flair)\n",
      "  Using cached huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect>=1.0.9 (from flair)\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lxml>=4.8.0 (from flair)\n",
      "  Downloading lxml-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting matplotlib>=2.2.3 (from flair)\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting more-itertools>=8.13.0 (from flair)\n",
      "  Using cached more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting mpld3>=0.3 (from flair)\n",
      "  Using cached mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair)\n",
      "  Using cached pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from flair) (2.9.0)\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
      "  Using cached pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting regex>=2022.1.18 (from flair)\n",
      "  Downloading regex-2024.9.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting scikit-learn>=1.0.2 (from flair)\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting segtok>=1.5.11 (from flair)\n",
      "  Using cached segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair)\n",
      "  Using cached sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate>=0.8.10 (from flair)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from flair) (2.4.1+cpu)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from flair) (4.66.5)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
      "  Using cached transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting transformers<5.0.0,>=4.18.0 (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Using cached transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair)\n",
      "  Using cached wikipedia_api-0.7.1.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting semver<4.0.0,>=3.0.0 (from flair)\n",
      "  Using cached semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting bioc<3.0.0,>=2.0.0 (from flair)\n",
      "  Using cached bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Using cached jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Using cached intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting botocore<1.36.0,>=1.35.49 (from boto3>=1.20.27->flair)\n",
      "  Using cached botocore-1.35.49-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair)\n",
      "  Using cached s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.13->flair)\n",
      "  Downloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
      "Collecting beautifulsoup4 (from gdown>=4.4.0->flair)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from gdown>=4.4.0->flair) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
      "Requirement already satisfied: six in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=2.2.3->flair)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=2.2.3->flair)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=2.2.3->flair)\n",
      "  Downloading fonttools-4.54.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib>=2.2.3->flair)\n",
      "  Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from matplotlib>=2.2.3->flair) (1.24.4)\n",
      "Collecting pillow>=6.2.0 (from matplotlib>=2.2.3->flair)\n",
      "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=2.2.3->flair)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib>=2.2.3->flair)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: jinja2 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from mpld3>=0.3->flair) (3.1.4)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn>=1.0.2->flair)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=1.0.2->flair)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=1.0.2->flair)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sympy in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from torch!=1.8,>=1.5.0->flair) (3.1)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading safetensors-0.4.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading tokenizers-0.20.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: protobuf in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (5.28.3)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
      "  Downloading sentencepiece-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.36.0,>=1.35.49->boto3>=1.20.27->flair)\n",
      "  Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib>=2.2.3->flair)\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=19.2.0 (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting accelerate>=0.26.0 (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair)\n",
      "  Using cached accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown>=4.4.0->flair)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from jinja2->mpld3>=0.3->flair) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from requests[socks]->gdown>=4.4.0->flair) (2024.8.30)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.4.0->flair)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
      "Requirement already satisfied: psutil in /home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.0)\n",
      "Using cached flair-0.14.0-py3-none-any.whl (776 kB)\n",
      "Using cached bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Using cached boto3-1.35.49-py3-none-any.whl (139 kB)\n",
      "Using cached conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
      "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Using cached huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
      "Downloading lxml-5.3.0-cp38-cp38-manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Using cached mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "Using cached pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading regex-2024.9.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Using cached semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached transformers-4.46.0-py3-none-any.whl (10.0 MB)\n",
      "Using cached botocore-1.35.49-py3-none-any.whl (12.6 MB)\n",
      "Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Using cached s3transfer-0.10.3-py3-none-any.whl (82 kB)\n",
      "Downloading safetensors-0.4.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.20.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Building wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=6b2d7ec8380baf54d23ec53636b3b2efe0bad63ed7686d9d9f92291f5aae89ba\n",
      "  Stored in directory: /home/swiftx/.cache/pip/wheels/13/c7/b0/79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=63e6d734b455b5e0ea7d4fe1b0da0b0486c428781a680c9b1117d5775a153202\n",
      "  Stored in directory: /home/swiftx/.cache/pip/wheels/e1/8b/30/5b20240d3d13a9dfafb6a6dd49d1b541c86d39812cb3690edf\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=2a184993e18b2599c24094897030bac87032bcdeef298a3a737e36af2fb047a0\n",
      "  Stored in directory: /home/swiftx/.cache/pip/wheels/04/c6/16/46e174009277f9bccdaa7215a243939d2f70180804b249bf3a\n",
      "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=4853b00e9078c9b349003ad3855b379466a07f8f359445c0859ab1a644ceeea3\n",
      "  Stored in directory: /home/swiftx/.cache/pip/wheels/b6/01/28/28561e3391ad2029d42a33bb3a88b37c996011a22fe4800e31\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=a0a1c20324393f47bd126427e752f068cf6d34c76ed0240e4df8de9f7e6a90f8\n",
      "  Stored in directory: /home/swiftx/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=a88d751747294fc6e2a906d0eb657d11d0ffb31819c7291f9b2e6c53ae8c491d\n",
      "  Stored in directory: /home/swiftx/.cache/pip/wheels/45/23/de/5789a92962483fd33cb06674792b9697c1b3766d7c7742830e\n",
      "Successfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\n",
      "Installing collected packages: sqlitedict, sortedcontainers, sentencepiece, pptree, docopt, zipp, wrapt, urllib3, threadpoolctl, tabulate, soupsieve, semver, scipy, safetensors, regex, PySocks, pyparsing, pillow, more-itertools, lxml, langdetect, kiwisolver, joblib, jmespath, intervaltree, ftfy, fonttools, cycler, contourpy, conllu, attrs, segtok, scikit-learn, jsonlines, importlib-resources, deprecated, botocore, beautifulsoup4, wikipedia-api, s3transfer, pytorch-revgrad, matplotlib, huggingface-hub, bioc, tokenizers, mpld3, gdown, boto3, accelerate, transformers, transformer-smaller-training-vocab, flair\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "Successfully installed PySocks-1.7.1 accelerate-1.0.1 attrs-24.2.0 beautifulsoup4-4.12.3 bioc-2.1 boto3-1.35.49 botocore-1.35.49 conllu-4.5.3 contourpy-1.1.1 cycler-0.12.1 deprecated-1.2.14 docopt-0.6.2 flair-0.14.0 fonttools-4.54.1 ftfy-6.2.3 gdown-5.2.0 huggingface-hub-0.26.1 importlib-resources-6.4.5 intervaltree-3.1.0 jmespath-1.0.1 joblib-1.4.2 jsonlines-4.0.0 kiwisolver-1.4.7 langdetect-1.0.9 lxml-5.3.0 matplotlib-3.7.5 more-itertools-10.5.0 mpld3-0.5.10 pillow-10.4.0 pptree-3.1 pyparsing-3.1.4 pytorch-revgrad-0.2.0 regex-2024.9.11 s3transfer-0.10.3 safetensors-0.4.5 scikit-learn-1.3.2 scipy-1.10.1 segtok-1.5.11 semver-3.0.2 sentencepiece-0.2.0 sortedcontainers-2.4.0 soupsieve-2.6 sqlitedict-2.1.0 tabulate-0.9.0 threadpoolctl-3.5.0 tokenizers-0.20.1 transformer-smaller-training-vocab-0.4.0 transformers-4.46.0 urllib3-1.26.20 wikipedia-api-0.7.1 wrapt-1.16.0 zipp-3.20.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swiftx/anaconda3/envs/stanza_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-27 13:17:32,338 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence[4]: \"I love Berlin .\" → [\"Berlin\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "# https://flairnlp.github.io/docs/category/tutorial-2-training-models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stanza_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
